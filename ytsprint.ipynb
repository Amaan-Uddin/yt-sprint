{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"jwROe6WH2lZi"},"outputs":[],"source":["Source = \"https://youtu.be/WIZw3hWlO9c?si=krjErpis69ZRCrRE\" #@param {type:\"string\"}\n","Type_of_source = \"Youtube video or playlist\" #@param ['Youtube video or playlist', 'Google Drive video link','Dropbox video link', 'Local file']\n","Type = Type_of_source\n","URL = Source\n","\n","#@markdown ---\n","#@markdown Insert your API key depending on which endpoint you want to use\n","# API Configuration\n","api_key = \"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\"  # @param {type:\"string\"}\n","api_endpoint = \"Groq\"  # @param ['Groq', 'OpenAI', 'Custom']\n","\n","endpoints = {\n","    \"Groq\": \"https://api.groq.com/openai/v1\",\n","    \"OpenAI\": \"https://api.openai.com/v1\",\n","    \"Custom\": \"http://localhost:1234/v1\"  # Example custom endpoint\n","}\n","base_url = endpoints.get(api_endpoint)\n","\n","models = {\n","    \"Groq\": \"llama3-8b-8192\",\n","    \"OpenAI\": \"gpt-4o-mini\",\n","    \"Custom\": \"Meta-Llama-3-8B-Instruct-GGUF\"  # Placeholder for any custom model\n","}\n","model = models.get(api_endpoint)\n","\n","use_Youtube_captions = True #@param {type:\"boolean\"}\n"]},{"cell_type":"markdown","metadata":{"id":"8WPgWnMQKgJv"},"source":["## Installation of libraries\n","Re-run if you change settings in the previous cell:"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","collapsed":true,"id":"sJnZWCPc3uOH","executionInfo":{"status":"ok","timestamp":1724179914777,"user_tz":-330,"elapsed":11012,"user":{"displayName":"MOHAMMED AMAANUDDIN 160421733108","userId":"02249429202158410448"}},"outputId":"258758da-59fe-4301-d32d-05f2bfdcea7f","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: youtube-transcript-api in /usr/local/lib/python3.10/dist-packages (0.6.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from youtube-transcript-api) (2.32.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->youtube-transcript-api) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->youtube-transcript-api) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->youtube-transcript-api) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->youtube-transcript-api) (2024.7.4)\n","Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.41.1)\n","Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n","Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n","Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.27.0)\n","Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.5.0)\n","Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.8.2)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n","Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.5)\n","Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n","Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.7)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.7.4)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\n","Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n","Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.20.1)\n","Collecting git+https://github.com/pytube/pytube\n","  Cloning https://github.com/pytube/pytube to /tmp/pip-req-build-qcbd9gyt\n","  Running command git clone --filter=blob:none --quiet https://github.com/pytube/pytube /tmp/pip-req-build-qcbd9gyt\n","  Resolved https://github.com/pytube/pytube to commit a32fff39058a6f7e5e59ecd06a7467b71197ce35\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n"]}],"source":["# %%capture\n","import subprocess\n","import re\n","import os\n","\n","if use_Youtube_captions:\n","  !pip install youtube-transcript-api\n","  from youtube_transcript_api import YouTubeTranscriptApi\n","\n","if (not Type == \"Youtube video or playlist\") or (not use_Youtube_captions):\n","  !pip install openai-whisper\n","  import whisper\n","\n","!pip install openai\n","import openai\n","client = openai.OpenAI(api_key=api_key, base_url=base_url)\n","\n","\n","if Type == \"Youtube video or playlist\":\n","  !pip install git+https://github.com/pytube/pytube\n","  from pytube import YouTube\n","\n","if Type == \"Google Drive video link\":\n","  from google.colab import drive\n","  drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"id":"WLMk2b_xKgJw"},"source":["## Video fetching\n","Re-run cell if you change the source URL:"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"eLIU6bAX9a9v"},"outputs":[],"source":["skip_transcription=False\n","text = \"\"\n","textTimestamps = \"\"\n","\n","def seconds_to_time_format(seconds):\n","    hours, remainder = divmod(seconds, 3600)\n","    minutes, seconds = divmod(remainder, 60)\n","    return f\"{int(hours):02d}:{int(minutes):02d}:{int(seconds):02d}\"\n","\n","def download_youtube_audio_only(url):\n","    yt = YouTube(url)\n","    audio_stream = yt.streams.get_audio_only()\n","    saved_path = audio_stream.download(output_path=\".\", skip_existing=True)\n","    return saved_path\n","\n","def download_youtube_captions(url):\n","    regex = r'(?:https?:\\/\\/)?(?:www\\.)?(?:youtube\\.com\\/(?:[^\\/\\n\\s]+\\/\\S+\\/|(?:v|e(?:mbed)?)\\/|\\S*?[?&]v=)|youtu\\.be\\/)([a-zA-Z0-9_-]{11})'\n","    video_id =  re.search(regex, url).group(1)\n","    transcript_list = YouTubeTranscriptApi.list_transcripts(video_id)\n","\n","    try:\n","      transcript = YouTubeTranscriptApi.get_transcript(video_id, languages=['en'])\n","    except:\n","      for available_transcript in transcript_list:\n","        if available_transcript.is_translatable:\n","          transcript = available_transcript.translate('en').fetch()\n","          break\n","\n","    text = \"\"\n","    for entry in transcript:\n","            start_time = seconds_to_time_format(entry['start'])\n","            text += f\"{start_time} {entry['text'].strip()}\\n\"\n","\n","    transcript_file_name = f\"{video_id}_captions.md\"\n","\n","    with open(transcript_file_name, 'w', encoding='utf-8') as f:\n","      f.write(text)\n","\n","    return text,transcript_file_name\n","\n","if Type == \"Youtube video or playlist\":\n","    #clean youtube url from timestamp\n","    URL = re.sub('\\&t=\\d+s?', '', URL)\n","    if use_Youtube_captions:\n","      text, transcript_file_name = download_youtube_captions(URL)\n","      skip_transcription=True\n","    else:\n","      video_path_local =  download_youtube_audio_only(URL)\n","\n","elif Type == \"Google Drive video link\":\n","  subprocess.run(['ffmpeg', '-y', '-i', \"drive/MyDrive/\" + URL, '-vn', '-acodec', 'pcm_s16le',\n","                  '-ar', '16000', '-ac', '1', 'gdrive_audio.wav'], check=True)\n","  video_path_local = \"gdrive_audio.wav\"\n","\n","elif Type == \"Dropbox video link\":\n","    subprocess.run(['wget', URL, '-O', 'dropbox_video.mp4'], check=True)\n","    subprocess.run(['ffmpeg', '-y', '-i', 'dropbox_video.mp4', '-vn', '-acodec', 'pcm_s16le',\n","                    '-ar', '16000', '-ac', '1', 'dropbox_video_audio.wav'], check=True)\n","    video_path_local = \"dropbox_video_audio.wav\"\n","\n","elif Type == \"Local file\":\n","    local_file_path = Source\n","    subprocess.run(['ffmpeg', '-y', '-i', local_file_path, '-vn', '-acodec', 'pcm_s16le',\n","                    '-ar', '16000', '-ac', '1', 'local_file_audio.wav'], check=True)\n","    video_path_local = \"local_file_audio.wav\""]},{"cell_type":"markdown","metadata":{"id":"vkJ7I1e1KgJy"},"source":["## Summarization and elaboration"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"fWeEGfgFAoni"},"outputs":[],"source":["prompt_type = \"Summarization\"  # @param ['Summarization', 'Only grammar correction with highlights']\n","# @markdown Set the number of parallel API calls (be mindful of usage rate limits)\n","parallel_api_calls = 10 # @param\n","\n","\n","# Define your prompts using a dictionary for easier management\n","prompts = {\n","    'Summarization': \"\"\"Summarize the video transcript excerpt including a concise title that reflects the content. Wrap the title with **markdown bold notation**. Write the summary as if you are continuing a conversation without needing to signal a beginning. Here is the transcript: \"\"\",\n","    'Only grammar correction with highlights': \"\"\"Repeat the following text correcting any grammatical errors and formatting error. Highlight only the important quote (if there are any) with **markdown bold notation**. Focus solely on the essence of the content as if you are continuing a conversation without using any form of introduction like 'Here's the corrected text:'. Here is the text to fix: \"\"\"\n","}\n","\n","# Select the appropriate prompt\n","summary_prompt = prompts[prompt_type]\n","\n","\n","def extract_and_clean_timestamps(text_chunks):\n","    timestamp_pattern = re.compile(r'(\\d{2}:\\d{2}:\\d{2})')\n","    cleaned_texts = []\n","    timestamp_ranges = []\n","    for chunk in text_chunks:\n","        timestamps = timestamp_pattern.findall(chunk)\n","        if timestamps:\n","            for timestamp in timestamps:\n","                # Remove each found timestamp from the chunk\n","                chunk = chunk.replace(timestamp, \"\")\n","            timestamp_ranges.append(timestamps[0])  # Assuming you want the first timestamp per chunk\n","        else:\n","            timestamp_ranges.append(\"\")\n","        cleaned_texts.append(chunk.strip())  # Strip to remove any leading/trailing whitespace\n","    return cleaned_texts, timestamp_ranges\n","\n","def format_timestamp_link(timestamp):\n","    if Type == \"Youtube video or playlist\":\n","      hours, minutes, seconds = map(int, timestamp.split(':'))\n","      total_seconds = hours * 3600 + minutes * 60 + seconds\n","      return f\"{timestamp} - {URL}&t={total_seconds}\"\n","    else:\n","      return f\"{timestamp}\"\n","\n","import concurrent.futures\n","import time\n","\n","def summarize(prompt):\n","    completion = client.chat.completions.create(\n","            model=model,\n","            messages=[\n","            {\"role\": \"system\", \"content\": summary_prompt},\n","            {\"role\": \"user\", \"content\": prompt}\n","            ],\n","            max_tokens=4096\n","    )\n","    return completion.choices[0].message.content\n","\n","def process_and_summarize(text):\n","    chunk_size, overlap_size = 4096, 20\n","    texts = [text[i:i+chunk_size] for i in range(0, len(text), chunk_size - overlap_size)]\n","    cleaned_texts, timestamp_ranges = extract_and_clean_timestamps(texts)\n","    summaries = []\n","\n","    with concurrent.futures.ThreadPoolExecutor(max_workers=parallel_api_calls) as executor:\n","        future_to_chunk = {executor.submit(summarize, text_chunk): idx for idx, text_chunk in enumerate(cleaned_texts)}\n","        for future in concurrent.futures.as_completed(future_to_chunk):\n","            idx = future_to_chunk[future]\n","            try:\n","                summarized_chunk = future.result()\n","                summary_piece = format_timestamp_link(timestamp_ranges[idx]) + \" \" + summarized_chunk\n","                summary_piece += \"\\n\"\n","                summaries.append((idx, summary_piece))\n","            except Exception as exc:\n","                print(f'Chunk {idx} generated an exception: {exc}')\n","                # Resubmit the task with the new model\n","                time.sleep(10)\n","                future_to_chunk[executor.submit(summarize, texts[idx])] = idx\n","\n","    summaries.sort()  # Ensure summaries are in the correct order\n","    final_summary = \"\\n\\n\".join([summary for _, summary in summaries])\n","\n","    # Save the final summary\n","    final_name = transcript_file_name.replace(\".md\", \"_FINAL.md\") if Type != \"Dropbox video link\" else \"final_dropbox_video.md\"\n","    with open(final_name, 'w') as f:\n","        f.write(final_summary)\n","\n","\n","process_and_summarize(text)"]}],"metadata":{"colab":{"provenance":[{"file_id":"121u4JqGnMy7rME8FNrwIYoqLwrxhb218","timestamp":1724180237003},{"file_id":"https://github.com/martinopiaggi/summarize/blob/main/Summarize.ipynb","timestamp":1721732181423}]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"}},"nbformat":4,"nbformat_minor":0}